{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''\n",
    "DESCRIPTION-------\n",
    "Example code for reading NVivo coded content from an NVivo extract into a pandas dataframe. \n",
    "Here we read in two files, one containing an extract of all NVivo coding except errors (everything_but_errors_12-22-20.xls), and \n",
    "another containing only the error coding (errors_12-22-20.xls). The code itself is trivial and the important points are contained in the NOTES.\n",
    "NOTES-------\n",
    "1) dependencies: the df.read_excel() in pandas uses the xlrd package internally, so you need to pip or conda install xlrd\n",
    "2) need to export the NVivo extract as an .xls file \n",
    "  - NOT .xlsx, because for some reason xlrd now only supports the older .xls file type\n",
    "  - NOT .csv because some cell values (description, coded text, maybe others) can contain commas and it is a hassle to work around this\n",
    "3) df.read_excel() cannot read the .xls file as directly exported from NVivo (NVivo's exported .xls file is malformed according to .read_excel()'s requirements)\n",
    "So as a workaround, you can \"repair\" NVivo's .xls file by doing the following (but the .xls files contained in ohtap/NVivo_output/data are already repaired, so \n",
    "no need to do this step unless you are working with .xls files you exported yourself from NVivo):\n",
    "   -open up the .xls file that was exported from NVivo in some spreadsheet software (I used mac's Numbers application, but Google Sheets or Excel would probably work too)\n",
    "   -re-export the opened file as another .xls file (which will now be well-formed for .read_excel()). In the Numbers application, what you do precisely is\n",
    "     + navigate to File -> Export To -> Excel...\n",
    "     + under \"Advanced Options\" change file type to .xls\n",
    "     + in the Excel Worksheets field, select \"One Per Table\" and nothing else (in particular, unselect \"Include a summary worksheet\" if that was selected by default\")\n",
    "     + click next and save the repaired file where you want\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#Set up directory structure however you want. Here the 'repaired' (as described above) .xls files are assumed to reside in the directory ./data/nvivo_content\n",
    "NVIVO_CONTENT_FP = os.path.join(\"data\", \"nvivo_content\")\n",
    "NOT_ERRORS_FP = os.path.join(NVIVO_CONTENT_FP, \"everything_but_errors_12-22-20.xls\")\n",
    "ERRORS_FP = os.path.join(NVIVO_CONTENT_FP, \"errors_12-22-20.xls\")\n",
    "\n",
    "METADATA_FP = os.path.join(\"data\", \"metadata-files\")\n",
    "INTERVIEWEES_METADATA_FP = os.path.join(METADATA_FP, \"OHTAP_metadata - Interviewees.csv\")\n",
    "\n",
    "everything_df = pd.read_excel(NOT_ERRORS_FP)\n",
    "errors_df = pd.read_excel(ERRORS_FP)\n",
    "ee_metadata = pd.read_csv(INTERVIEWEES_METADATA_FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nodes\\\\\\\\Event (Extent)', 'Nodes\\\\\\\\Event (Extent)\\\\Needs Review',\n",
       "       'Nodes\\\\\\\\Event (Initiating Question)',\n",
       "       'Nodes\\\\\\\\Event (Initiating Question)\\\\Needs Review',\n",
       "       'Nodes\\\\\\\\Narrative Type\\\\Needs Review',\n",
       "       'Nodes\\\\\\\\Narrative Type\\\\Observations and Cultural References',\n",
       "       'Nodes\\\\\\\\Narrative Type\\\\Personal Experience',\n",
       "       'Nodes\\\\\\\\Narrative Type\\\\Personal Experience\\\\Negative Response',\n",
       "       'Nodes\\\\\\\\Narrative Type\\\\Policy; Politics; Legal',\n",
       "       'Nodes\\\\\\\\Narrative Type\\\\Second-hand Account',\n",
       "       'Nodes\\\\\\\\Topic\\\\Interracial Event',\n",
       "       'Nodes\\\\\\\\Topic\\\\Needs Review',\n",
       "       'Nodes\\\\\\\\Topic\\\\Sexual assault or rape',\n",
       "       'Nodes\\\\\\\\Topic\\\\Sexual harassment'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect the string handles for all the different coding types\n",
    "all_coding_types = everything_df[\"Hierarchical Name\"].unique()\n",
    "all_coding_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set codes equal to the set of codes you want to count\n",
    "#codes = {'Nodes\\\\\\\\Topic\\\\Sexual assault or rape', 'Nodes\\\\\\\\Topic\\\\Sexual harassment'}\n",
    "codes = {'Nodes\\\\\\\\Topic\\\\Sexual assault or rape'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nodes\\\\Event (Extent)                                          1231\n",
       "Nodes\\\\Event (Initiating Question)                             1075\n",
       "Nodes\\\\Topic\\Sexual assault or rape                             758\n",
       "Nodes\\\\Narrative Type\\Policy; Politics; Legal                   504\n",
       "Nodes\\\\Narrative Type\\Observations and Cultural References      386\n",
       "Nodes\\\\Narrative Type\\Second-hand Account                       244\n",
       "Nodes\\\\Narrative Type\\Personal Experience                       242\n",
       "Nodes\\\\Topic\\Interracial Event                                  223\n",
       "Nodes\\\\Topic\\Sexual harassment                                  202\n",
       "Nodes\\\\Narrative Type\\Personal Experience\\Negative Response      45\n",
       "Nodes\\\\Narrative Type\\Needs Review                               27\n",
       "Nodes\\\\Event (Extent)\\Needs Review                               23\n",
       "Nodes\\\\Topic\\Needs Review                                        13\n",
       "Nodes\\\\Event (Initiating Question)\\Needs Review                   9\n",
       "Name: Hierarchical Name, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything_df[\"Hierarchical Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get everything coded as rape (i.e. where the Hierarchical Name field is 'Nodes\\\\\\\\Topic\\\\Sexual assault or rape')\n",
    "rape_events = everything_df[ everything_df['Hierarchical Name'].isin(codes) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Files\\\\HM                      436\n",
       "Files\\\\SCVF                    147\n",
       "Files\\\\UNCTWMS                  91\n",
       "Files\\\\BWOH                     26\n",
       "Files\\\\SCAARJ                   15\n",
       "Files\\\\SCAP                     10\n",
       "Files\\\\UNCSW                     8\n",
       "Files\\\\SCAL                      8\n",
       "Files\\\\SHSA                      5\n",
       "Files\\\\ROHA                      5\n",
       "Files\\\\SHSF                      2\n",
       "Files\\\\Missing OSS and SOOH      2\n",
       "Files\\\\BWSP                      2\n",
       "Files\\\\UNCGAS                    1\n",
       "Name: Folder Location, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get counts of rape event by collection\n",
    "rape_events[\"Folder Location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts of interviews that have at least one rape event, by collection\n",
    "list_of_interviews_with_rape_event = list(rape_events[\"Hierarchical Name.1\"].unique())\n",
    "\n",
    "counts_by_collection = defaultdict(lambda:0)\n",
    "for interview in list_of_interviews_with_rape_event:\n",
    "    \n",
    "    collection = interview.split('\\\\\\\\')[1]\n",
    "    counts_by_collection[collection] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'BWOH': 18,\n",
       "             'BWSP': 2,\n",
       "             'HM': 161,\n",
       "             'Missing OSS and SOOH': 2,\n",
       "             'ROHA': 5,\n",
       "             'SCAARJ': 4,\n",
       "             'SCAL': 6,\n",
       "             'SCAP': 8,\n",
       "             'SCVF': 35,\n",
       "             'SHSA': 2,\n",
       "             'SHSF': 2,\n",
       "             'UNCGAS': 1,\n",
       "             'UNCSW': 7,\n",
       "             'UNCTWMS': 34})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#manual counts of number of interviews in each collection, followed by description of how count was arrived at\n",
    "#TODO: clean up organization of transcripts on google drive so we know how many\n",
    "#interviews are in each collection and can easily get .txt files for them\n",
    "total_interviews_per_collection = {\n",
    "    #'BWOH': 18,\n",
    "             #'BWSP': 2,\n",
    "             'HM': 2687, #number of .txt files in download of HM transcripts from Google drive\n",
    "             #'Missing OSS and SOOH': 2,\n",
    "             #'ROHA': 5,\n",
    "             #'SCAARJ': 4,\n",
    "             #'SCAL': 6,\n",
    "             #'SCAP': 8,\n",
    "             'SCVF': 247, # UNCERTAIN, just comes from adding up counts of Smith college related interviews on Collection Info spreadsheet\n",
    "             #'SHSA': 2,\n",
    "             #'SHSF': 2,\n",
    "             #'UNCGAS': 1,\n",
    "             #'UNCSW': 7,\n",
    "             #'UNCTWMS': 34}\n",
    "}\n",
    "'''\n",
    "\n",
    "total_interviews_per_collection = dict(ee_metadata['collection_id'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HM': 2687,\n",
       " 'OSS': 411,\n",
       " 'SOOH': 303,\n",
       " 'SCAP': 199,\n",
       " 'UNCTWMS': 167,\n",
       " 'BWSP': 164,\n",
       " 'OWDB': 143,\n",
       " 'RTRB': 123,\n",
       " 'OCFF': 118,\n",
       " 'OOHYLC': 111,\n",
       " 'ROHA': 80,\n",
       " 'BWOH': 72,\n",
       " 'ONA': 69,\n",
       " 'UNCSW': 67,\n",
       " 'SCVF': 51,\n",
       " 'ONA; SOOH': 49,\n",
       " 'SHSF': 47,\n",
       " 'WOL': 47,\n",
       " 'OWHF': 36,\n",
       " 'SHSA': 30,\n",
       " 'UNCGAS': 30,\n",
       " 'SCAL': 15,\n",
       " 'SCAARJ': 14,\n",
       " 'SNAI': 13,\n",
       " 'ONA; OWHF; SOOH': 1,\n",
       " 'OSS; SOOH': 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_interviews_per_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BWOH: 0.250\n",
      "BWSP: 0.012\n",
      "HM: 0.060\n",
      "ROHA: 0.062\n",
      "SCAARJ: 0.286\n",
      "SCAL: 0.400\n",
      "SCAP: 0.040\n",
      "SCVF: 0.686\n",
      "SHSA: 0.067\n",
      "SHSF: 0.043\n",
      "UNCGAS: 0.033\n",
      "UNCSW: 0.104\n",
      "UNCTWMS: 0.204\n"
     ]
    }
   ],
   "source": [
    "for key, val in counts_by_collection.items():\n",
    "    if key in total_interviews_per_collection:\n",
    "        n_hit = counts_by_collection[key]\n",
    "        n_total = total_interviews_per_collection[key]\n",
    "        proportion = n_hit / n_total \n",
    "        print(\"{}: {:.3f}\".format(key, proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare a .csv file with columns \"collection_name\", \"interviews_with_CODES\", \"total_interviews\", \"percentage_of_collection\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_hit = pd.Series(counts_by_collection).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = pd.Series(total_interviews_per_collection).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([n_hit, n_total], axis=1).dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: \"interviews_with_CODES\", 1: \"total_interviews\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"percentage_of_collection\"] = df[\"interviews_with_CODES\"]/df[\"total_interviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"index\": \"collection_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.rename(columns={\"interviews_with_CODES\": \"interviews_with_rape_topic_code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>interviews_with_rape_topic_code</th>\n",
       "      <th>total_interviews</th>\n",
       "      <th>percentage_of_collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BWOH</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BWSP</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HM</td>\n",
       "      <td>161</td>\n",
       "      <td>2687</td>\n",
       "      <td>0.059918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROHA</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCAARJ</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCAL</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCAP</td>\n",
       "      <td>8</td>\n",
       "      <td>199</td>\n",
       "      <td>0.040201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SCVF</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SHSA</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SHSF</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UNCGAS</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UNCSW</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>0.104478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UNCTWMS</td>\n",
       "      <td>34</td>\n",
       "      <td>167</td>\n",
       "      <td>0.203593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_id  interviews_with_rape_topic_code  total_interviews  \\\n",
       "0           BWOH                               18                72   \n",
       "1           BWSP                                2               164   \n",
       "2             HM                              161              2687   \n",
       "3           ROHA                                5                80   \n",
       "4         SCAARJ                                4                14   \n",
       "5           SCAL                                6                15   \n",
       "6           SCAP                                8               199   \n",
       "7           SCVF                               35                51   \n",
       "8           SHSA                                2                30   \n",
       "9           SHSF                                2                47   \n",
       "10        UNCGAS                                1                30   \n",
       "11         UNCSW                                7                67   \n",
       "12       UNCTWMS                               34               167   \n",
       "\n",
       "    percentage_of_collection  \n",
       "0                   0.250000  \n",
       "1                   0.012195  \n",
       "2                   0.059918  \n",
       "3                   0.062500  \n",
       "4                   0.285714  \n",
       "5                   0.400000  \n",
       "6                   0.040201  \n",
       "7                   0.686275  \n",
       "8                   0.066667  \n",
       "9                   0.042553  \n",
       "10                  0.033333  \n",
       "11                  0.104478  \n",
       "12                  0.203593  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
